{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCu1mXACaKdx"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZoxseEX7_Fy1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxES-OQfaZaF"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GApOWb8K_QbC"
   },
   "outputs": [],
   "source": [
    "T = 10  # Diffusion steps\n",
    "embed_dim = 10  # Label embedding dimension, since we use one-hot encoding, d = num of classes \n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vzSRvuN-_QUv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: tensor([0.9000, 0.8300, 0.7600, 0.6900, 0.6200, 0.5500, 0.4800, 0.4100, 0.3400,\n",
      "        0.2700, 0.2000])\n",
      "Alpha_bar: tensor([0.0005, 0.0005, 0.0006, 0.0009, 0.0012, 0.0020, 0.0036, 0.0075, 0.0184,\n",
      "        0.0540, 0.2000])\n",
      "SNR: tensor([0.0005, 0.0005, 0.0006, 0.0009, 0.0012, 0.0020, 0.0036, 0.0076, 0.0187,\n",
      "        0.0571, 0.2500])\n",
      "a_t: tensor([   nan, 0.0023, 0.0043, 0.0070, 0.0109, 0.0170, 0.0271, 0.0453, 0.0806,\n",
      "        0.1562, 0.3451])\n",
      "b_t: tensor([   nan, 0.0220, 0.0232, 0.0254, 0.0291, 0.0351, 0.0445, 0.0599, 0.0858,\n",
      "        0.1306, 0.1965])\n",
      "c_t: tensor([   nan, 0.1000, 0.1700, 0.2400, 0.3099, 0.3797, 0.4493, 0.5180, 0.5836,\n",
      "        0.6360, 0.6173])\n"
     ]
    }
   ],
   "source": [
    "# Noise schedule (linear)\n",
    "alpha = torch.linspace(0.9, 0.2, T+1)  # α_t from 0.9 → 0.2\n",
    "alpha_bar = torch.cumprod(alpha.flip(0), dim=0).flip(0)\n",
    "\n",
    "print(\"Alpha:\", alpha)\n",
    "print(\"Alpha_bar:\", alpha_bar)\n",
    "\n",
    "SNR = alpha_bar / (1 - alpha_bar)  # Signal-to-noise ratio\n",
    "\n",
    "# For computing a_t, b_t, c_t we need α_{t-1} and also the previous alpha bar \n",
    "alpha_bar_prev = torch.cat([torch.tensor([torch.nan]), alpha_bar[:-1]])\n",
    "alpha_prev = torch.cat([torch.tensor([torch.nan]), alpha[:-1]])\n",
    "\n",
    "a = torch.sqrt(alpha_bar) * (1 - alpha_prev) / (1 - alpha_bar_prev)\n",
    "b = torch.sqrt(alpha_bar_prev) * (1 - alpha_bar) / (1 - alpha_bar_prev)\n",
    "c = (1 - alpha_bar) * (1 - alpha_prev) / (1 - alpha_bar_prev)\n",
    "\n",
    "print(\"SNR:\", SNR)\n",
    "print(\"a_t:\", a)\n",
    "print(\"b_t:\", b) \n",
    "print(\"c_t:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeZ3MSd3adhn"
   },
   "source": [
    "# Setting Up Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uJ26Tb7Z_QQR"
   },
   "outputs": [],
   "source": [
    "# MLP for denoising\n",
    "class BlockNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.final_dim_img = 32\n",
    "\n",
    "        self.cnn =  nn.Sequential(  # process image x\n",
    "            nn.Conv2d(1, 16, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(16, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, self.final_dim_img)\n",
    "        )\n",
    "\n",
    "        self.mlp1 = nn.Sequential(  # process previous layer activation z_{t-1}\n",
    "            nn.Linear(embed_dim, 64),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, embed_dim)     \n",
    "        )\n",
    "\n",
    "        self.mlp2 = nn.Sequential(  # process the concatenation of the previous two NN\n",
    "            nn.Linear(self.final_dim_img + embed_dim, 256),  # Input: image features + noisy label features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, embed_dim)        # Output: approximate de-noised label u^ \n",
    "        )\n",
    "\n",
    "    def forward(self, x, z_t):\n",
    "        img_features = self.cnn(x)\n",
    "        processed_activation = self.mlp1(z_t)\n",
    "\n",
    "        combined = torch.cat([img_features, processed_activation], dim=1)  # returns u^ at block t+1\n",
    "        return self.mlp2(combined)  # Fixed: was self.mlp, should be self.mlp2\n",
    "    \n",
    "\n",
    "# Initialize models\n",
    "blockNN = nn.ModuleList([None] + [BlockNN() for _ in range(T)])  # Index 0 is None, blocks 1 to T\n",
    "optimizers = [optim.Adam(blockNN[i].parameters(), lr=lr) for i in range(1, T+1)]  # Only create optimizers for actual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DenoisingMLP Structure ===\n",
      "\n",
      "CNN Component Summary:\n",
      "Input: (1, 28, 28) - MNIST grayscale image\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [128, 16, 26, 26]             160\n",
      "              ReLU-2          [128, 16, 26, 26]               0\n",
      "         MaxPool2d-3            [128, 16, 6, 6]               0\n",
      "            Conv2d-4            [128, 32, 4, 4]           4,640\n",
      "              ReLU-5            [128, 32, 4, 4]               0\n",
      "         MaxPool2d-6            [128, 32, 2, 2]               0\n",
      "           Flatten-7                 [128, 128]               0\n",
      "            Linear-8                  [128, 32]           4,128\n",
      "================================================================\n",
      "Total params: 8,928\n",
      "Trainable params: 8,928\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 22.97\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 23.39\n",
      "----------------------------------------------------------------\n",
      "\n",
      "MLP Component Summary:\n",
      "Input: (138,) - CNN features + noisy label\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [128, 256]          11,008\n",
      "              ReLU-2                 [128, 256]               0\n",
      "            Linear-3                  [128, 10]           2,570\n",
      "================================================================\n",
      "Total params: 13,578\n",
      "Trainable params: 13,578\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.51\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DenoisingMLP Structure ===\")\n",
    "_b = blockNN[1] \n",
    "\n",
    "print(\"\\nCNN Component Summary:\")\n",
    "print(\"Input: (1, 28, 28) - MNIST grayscale image\")\n",
    "summary(_b.cnn, (1, 28, 28), batch_size=batch_size)\n",
    "\n",
    "print(f\"\\nMLP Component Summary:\")\n",
    "print(f\"Input: ({128 + embed_dim},) - CNN features + noisy label\")\n",
    "summary(_b.mlp2, (32 + embed_dim,), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY3BUc9Dah44"
   },
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZAWOkNB_xuF",
    "outputId": "3acd5dba-09e9-40a9-cd8c-16e8a87d6ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST with train-test split\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lgU9EC0amwQ"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy calculation function\n",
    "def calculate_accuracy(data_loader, blockNN, T = T, embed_dim = embed_dim):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            current_batch_size = x.shape[0]\n",
    "            \n",
    "            # Start from pure noise t = 0\n",
    "            z_t = torch.randn(current_batch_size, embed_dim)\n",
    "            \n",
    "            # Forward pass through all blocks\n",
    "            for t in range(1, T+1):\n",
    "                u_hat = blockNN[t](x, z_t)\n",
    "                z_t = a[t] * u_hat + b[t] * z_t + torch.sqrt(c[t]) * torch.randn(current_batch_size, embed_dim)\n",
    "                \n",
    "                if t == T:  # For final block, get predictions\n",
    "                    predictions = torch.argmax(z_t, dim=1)\n",
    "                    correct += (predictions == y).sum().item()\n",
    "                    total += y.size(0)\n",
    "    \n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtGT_c1H_y9r",
    "outputId": "2ae2430a-4e96-4e08-9ce6-1e7bc7b719ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Avg Loss: 0.7269 | Train Acc: 0.9241 | Test Acc: 0.9354\n",
      "Epoch 2/10 | Avg Loss: 0.1867 | Train Acc: 0.9495 | Test Acc: 0.9553\n",
      "Epoch 2/10 | Avg Loss: 0.1867 | Train Acc: 0.9495 | Test Acc: 0.9553\n",
      "Epoch 3/10 | Avg Loss: 0.1291 | Train Acc: 0.9608 | Test Acc: 0.9656\n",
      "Epoch 3/10 | Avg Loss: 0.1291 | Train Acc: 0.9608 | Test Acc: 0.9656\n",
      "Epoch 4/10 | Avg Loss: 0.1040 | Train Acc: 0.9670 | Test Acc: 0.9704\n",
      "Epoch 4/10 | Avg Loss: 0.1040 | Train Acc: 0.9670 | Test Acc: 0.9704\n",
      "Epoch 5/10 | Avg Loss: 0.0890 | Train Acc: 0.9757 | Test Acc: 0.9781\n",
      "Epoch 5/10 | Avg Loss: 0.0890 | Train Acc: 0.9757 | Test Acc: 0.9781\n",
      "Epoch 6/10 | Avg Loss: 0.0790 | Train Acc: 0.9797 | Test Acc: 0.9812\n",
      "Epoch 6/10 | Avg Loss: 0.0790 | Train Acc: 0.9797 | Test Acc: 0.9812\n",
      "Epoch 7/10 | Avg Loss: 0.0708 | Train Acc: 0.9735 | Test Acc: 0.9723\n",
      "Epoch 7/10 | Avg Loss: 0.0708 | Train Acc: 0.9735 | Test Acc: 0.9723\n",
      "Epoch 8/10 | Avg Loss: 0.0636 | Train Acc: 0.9828 | Test Acc: 0.9826\n",
      "Epoch 8/10 | Avg Loss: 0.0636 | Train Acc: 0.9828 | Test Acc: 0.9826\n",
      "Epoch 9/10 | Avg Loss: 0.0616 | Train Acc: 0.9806 | Test Acc: 0.9809\n",
      "Epoch 9/10 | Avg Loss: 0.0616 | Train Acc: 0.9806 | Test Acc: 0.9809\n",
      "Epoch 10/10 | Avg Loss: 0.0540 | Train Acc: 0.9825 | Test Acc: 0.9812\n",
      "Training complete!\n",
      "Epoch 10/10 | Avg Loss: 0.0540 | Train Acc: 0.9825 | Test Acc: 0.9812\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        current_batch_size = x.shape[0]\n",
    "        u_y = torch.zeros(current_batch_size, embed_dim).scatter_(1, y.unsqueeze(1), 1) # create a one-hot encoding tensor shape = (batch_size, embed_dim)\n",
    "\n",
    "        # Forward diffusion (Adding Noise for each layer -> Variance Preserving (VP) Process)\n",
    "        z = [torch.randn_like(u_y)] # starts with pure noise (z_0)\n",
    "\n",
    "        for t in range(1, T + 1):  # for each layer t = 1, ..., T:\n",
    "            eps = torch.randn_like(u_y)\n",
    "            z_t = torch.sqrt(alpha_bar[t]) * u_y + torch.sqrt(1 - alpha_bar[t]) * eps   # z_t sampled form N(sqrt{alpha_bar[t]} u_y, (1-alpha_bar[t])*eps)  \n",
    "            z.append(z_t)\n",
    "\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        # Inner Blocks 1, ..., T - 1\n",
    "        for t in range(1, T):\n",
    "            u_hat_t = blockNN[t](x, z[t-1].detach())  # stops tracking operations on z[t-1] tensor for gradient calculation.  *** -1 on blockNN used to get the right block in the list\n",
    "            losses.append((SNR[t] - SNR[t-1]) * torch.mean((u_hat_t - u_y) ** 2))\n",
    "\n",
    "        # Classification Head t = T\n",
    "        u_hat_T = blockNN[T](x, z[T-1].detach())\n",
    "        z_T = a[T] * u_hat_T + b[T] * z[T-1] + torch.sqrt(c[T]) * torch.randn(current_batch_size, embed_dim)\n",
    "        losses.append(F.cross_entropy(z_T, y))   # it internally compute log_softmax of z_T\n",
    "\n",
    "        total_loss = sum(losses)\n",
    "        for opt in optimizers:\n",
    "            opt.zero_grad()  # clear gradients from previous iteration\n",
    "            \n",
    "        total_loss.backward()  # find the gradient across all parameters, note that parameters of a layers don't change gradient for another one\n",
    "        for opt in optimizers:\n",
    "            opt.step()  # each optimizer perform the update of its block parameters\n",
    "\n",
    "        epoch_loss += total_loss.item()\n",
    "        batch_count += 1\n",
    "\n",
    "    # Epoch summary print with accuracy\n",
    "    avg_loss = epoch_loss / batch_count\n",
    "    \n",
    "    train_acc = calculate_accuracy(train_loader, blockNN)\n",
    "    test_acc = calculate_accuracy(test_loader, blockNN)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Avg Loss: {avg_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "# Final message\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Save model weights\n",
    "torch.save(blockNN.state_dict(), 'blockNN_weights.pth')\n",
    "print(\"Model weights saved to 'blockNN_weights.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGrsvukHaqGX"
   },
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LINA1yBV_0XH"
   },
   "outputs": [],
   "source": [
    "# Inference (denoising)\n",
    "def predict(x):\n",
    "    with torch.no_grad():\n",
    "        z_t = torch.randn(1, embed_dim)  # Start from noise\n",
    "        \n",
    "        for t in range(1, T+1):  # Start from 1, not 0\n",
    "            u_hat = blockNN[t](x.unsqueeze(0), z_t)\n",
    "            z_t = a[t] * u_hat + b[t] * z_t + torch.sqrt(c[t]) * torch.randn(1, embed_dim)\n",
    "            if t == T:  # For final block, return prediction\n",
    "                return torch.argmax(z_t, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qs8kIZcb_0Tp",
    "outputId": "8823f70e-d3f6-4eb8-c2a6-bd771136c828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tensor([2]), True: 2\n"
     ]
    }
   ],
   "source": [
    "# Test on a random example\n",
    "test_loader_shuffled = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "x_test, y_test = next(iter(test_loader_shuffled))\n",
    "random_idx = random.randint(0, batch_size-1)\n",
    "pred = predict(x_test[random_idx])\n",
    "print(f\"Predicted: {pred}, True: {y_test[random_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XTHv45S5_0RO"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_prediction(x, true_label, pred_label, class_names=None):\n",
    "    \"\"\"\n",
    "    Plot image with true and predicted labels.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Input image tensor (1, C, H, W)\n",
    "        true_label (int): Ground truth class index\n",
    "        pred_label (int): Predicted class index\n",
    "        class_names (list): Optional list of class names\n",
    "    \"\"\"\n",
    "    # Convert tensor to numpy and denormalize if needed\n",
    "    img = x.squeeze().cpu().numpy()\n",
    "    if img.min() < 0 or img.max() > 1:  # Assuming [0,1] or [-1,1] range\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(6, 3))\n",
    "\n",
    "    # Plot image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "    plt.axis('off')\n",
    "    plt.title('Input Image', pad=10)\n",
    "\n",
    "    # Plot labels\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "\n",
    "    if class_names:\n",
    "        true_str = f\"True: {class_names[true_label]}\"\n",
    "        pred_str = f\"Predicted: {class_names[pred_label]}\"\n",
    "    else:\n",
    "        true_str = f\"True label: {true_label}\"\n",
    "        pred_str = f\"Predicted: {pred_label}\"\n",
    "\n",
    "    plt.text(0.1, 0.7, true_str, fontsize=12, color='green')\n",
    "    plt.text(0.1, 0.5, pred_str,\n",
    "             fontsize=12,\n",
    "             color='red' if true_label != pred_label else 'green')\n",
    "\n",
    "    # Highlight incorrect predictions\n",
    "    if true_label != pred_label:\n",
    "        plt.text(0.1, 0.3, \"INCORRECT\", fontsize=14, color='red', weight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "WK1nzjCt_0O-",
    "outputId": "d3afcc0a-d137-4ad0-dec9-e1a7fe0faa07"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage with MNIST\n",
    "class_names = [str(i) for i in range(10)]  # ['0', '1', ..., '9']\n",
    "test_loader_shuffled = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "x_test, y_test = next(iter(test_loader_shuffled))\n",
    "random_idx = random.randint(0, batch_size-1)\n",
    "pred = predict(x_test[random_idx])\n",
    "\n",
    "plot_prediction(x_test[random_idx],\n",
    "               y_test[random_idx].item(),\n",
    "               pred.item(),\n",
    "               class_names)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOg0HFF5C/8CLWLLGaczBlp",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
